{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pgvector quickstart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import dotenv\n",
    "\n",
    "\n",
    "# Reload the variables in your '.env' file (override the existing variables)\n",
    "dotenv.load_dotenv(\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..'))) # Add the parent directory to the path since we work with notebooks\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "from logging_utils import get_logger, global_log_config\n",
    "\n",
    "\n",
    "global_log_config(\n",
    "    log_level=logging.getLevelName(\"DEBUG\"),\n",
    "    json=False,\n",
    ")\n",
    "\n",
    "\n",
    "# # Load environment variables from a .env file\n",
    "# load_dotenv()\n",
    "\n",
    "# # Set the OpenAI API key environment variable\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://www.youtube.com/watch?v=Ff3tJ4pJEa4\n",
    "import pinecone\n",
    "from dotenv import load_dotenv\n",
    "from pgvector_service import PgvectorService\n",
    "import os\n",
    "import time\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import PGVector, Pinecone\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the documents\n",
    "\n",
    "> 4. Initialize a LangChain vector store\n",
    "> Now that you've built your Pinecone index, you need to initialize a LangChain vector store using the index. This step uses the OpenAI API key you set as an environment variable earlier. Note that OpenAI is a paid service and so running the \n",
    "> remainder of this tutorial may incur some small cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFirst, we compare to Pinecone, a managed vector store service.\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\n",
    "    \"../../data/The Project Gutenberg eBook of A Christmas Carol in Prose; Being a Ghost Story of Christmas.txt\"\n",
    ")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create a unique ID for each document\n",
    "# SOURCE: https://github.com/theonemule/azure-rag-sample/blob/1e37de31678ffbbe5361a8ef3acdb770194f462a/import.py#L4\n",
    "for idx, doc in enumerate(docs):\n",
    "    doc.metadata[\"id\"] = str(idx)\n",
    "\n",
    "# vectorstore.add_documents(docs, ids=[doc.metadata[\"id\"] for doc in docs])\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# get openai api key from platform.openai.com\n",
    "model_name = 'text-embedding-ada-002'\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "query = \"The Project Gutenberg eBook of A Christmas Carol in Prose; Being a Ghost Story of Christmas\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "First, we compare to Pinecone, a managed vector store service.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create / Load the Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'indexes'</span>: <span style=\"font-weight: bold\">[]}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'indexes'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 96}},\n",
       " 'total_vector_count': 96}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_serverless = True\n",
    "\n",
    "# pinecone.init(\n",
    "#     api_key=os.getenv(\"PINECONE_API_KEY\"), environment=os.getenv(\"PINECONE_ENV\")\n",
    "# )\n",
    "\n",
    "# SOURCE: https://docs.pinecone.io/integrations/langchain#4-initialize-a-langchain-vector-store\n",
    "\n",
    "import os\n",
    "# from pinecone.control.pinecone import Pinecone\n",
    "from pinecone.grpc.pinecone import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec, PodSpec\n",
    "import time\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import rich\n",
    "\n",
    "pc: Pinecone = Pinecone(\n",
    "    api_key=os.environ.get(\"PINECONE_API_KEY\")\n",
    ")\n",
    "\n",
    "if use_serverless:\n",
    "    spec = ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "else:\n",
    "    # if not using a starter index, you should specify a pod_type too\n",
    "    spec = PodSpec()\n",
    "\n",
    "index_name = \"demo-index\"\n",
    "\n",
    "\n",
    "# delete all indexes\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "\n",
    "rich.print(pc.list_indexes())\n",
    "rich.print(pc.list_indexes().names())\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "\n",
    "    pc.create_index(name=index_name, metric=\"cosine\", dimension=1536, spec=spec)\n",
    "\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=index_name, embedding=embeddings, text_key=\"text\"\n",
    "    )\n",
    "    vectorstore.add_documents(docs, ids=[doc.metadata[\"id\"] for doc in docs])\n",
    "\n",
    "else:\n",
    "    print(f\"Index {index_name} already exists\")\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=index_name, embedding=embeddings, text_key=\"text\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the LangChain vector store: \n",
    "\n",
    "> https://docs.pinecone.io/integrations/langchain#4-initialize-a-langchain-vector-store\n",
    "\n",
    "\n",
    "The text_field parameter sets the name of the metadata field that stores the raw text when you upsert records using a LangChain operation such as vectorstore.from_documents or vectorstore.add_texts. This metadata field is used as the page_content in the Document objects retrieved from query-like LangChain operations such as vectorstore.similarity_search. If you do not specify a value for text_field, it will default to \"text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "text_field = \"text\"\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=index_name, embedding=embeddings, text_key=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now you can query the vector store directly using vectorstore.similarity_search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': '0', 'source': '../../data/The Project Gutenberg eBook of A Christmas Carol in Prose; Being a Ghost Story of Christmas.txt'}, page_content=\"\\ufeffThe Project Gutenberg eBook of A Christmas Carol in Prose; Being a Ghost Story of Christmas\\n\\nThis ebook is for the use of anyone anywhere in the United States and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\nof the Project Gutenberg License included with this ebook or online\\nat www.gutenberg.org. If you are not located in the United States,\\nyou will have to check the laws of the country where you are located\\nbefore using this eBook.\\n\\nTitle: A Christmas Carol in Prose; Being a Ghost Story of Christmas\\n\\n\\nAuthor: Charles Dickens\\n\\nIllustrator: John Leech\\n\\nRelease date: August 11, 2004 [eBook #46]\\n                Most recently updated: October 17, 2021\\n\\nLanguage: English\\n\\n*** START OF THE PROJECT GUTENBERG EBOOK A CHRISTMAS CAROL IN PROSE; BEING A GHOST STORY OF CHRISTMAS ***\\n\\nA CHRISTMAS CAROL\\n\\nIN PROSE\\nBEING\\nA Ghost Story of Christmas\\n\\nby Charles Dickens\\n\\nPREFACE\\n\\nI HAVE endeavoured in this Ghostly little book,\\nto raise the Ghost of an Idea, which shall not put my\\nreaders out of humour with themselves, with each other,\\nwith the season, or with me.  May it haunt their houses\\npleasantly, and no one wish to lay it.\\n\\nTheir faithful Friend and Servant,\\n                                   C. D.\\nDecember, 1843.\\n\\nCONTENTS\\n\\nStave   I: Marley's Ghost\\nStave  II: The First of the Three Spirits\\nStave III: The Second of the Three Spirits\\nStave  IV: The Last of the Spirits\\nStave   V: The End of It\\n\\nSTAVE I:  MARLEY'S GHOST\\n\\nMARLEY was dead: to begin with. There is no doubt\\nwhatever about that. The register of his burial was\\nsigned by the clergyman, the clerk, the undertaker,\\nand the chief mourner. Scrooge signed it: and\\nScrooge's name was good upon 'Change, for anything he\\nchose to put his hand to. Old Marley was as dead as a\\ndoor-nail.\"),\n",
       " Document(metadata={'id': '91', 'source': '../../data/The Project Gutenberg eBook of A Christmas Carol in Prose; Being a Ghost Story of Christmas.txt'}, page_content='He had no further intercourse with Spirits, but lived upon\\nthe Total Abstinence Principle, ever afterwards; and it was\\nalways said of him, that he knew how to keep Christmas\\nwell, if any man alive possessed the knowledge. May that\\nbe truly said of us, and all of us! And so, as Tiny Tim\\nobserved, God bless Us, Every One!\\n\\n\\n            *** END OF THE PROJECT GUTENBERG EBOOK A CHRISTMAS CAROL IN PROSE; BEING A GHOST STORY OF CHRISTMAS ***\\n\\n\\nUpdated editions will replace the previous one—the old editions will\\nbe renamed.\\n\\nCreating the works from print editions not protected by U.S. copyright\\nlaw means that no one owns a United States copyright in these works,\\nso the Foundation (and you!) can copy and distribute it in the United\\nStates without permission and without paying copyright\\nroyalties. Special rules, set forth in the General Terms of Use part\\nof this license, apply to copying and distributing Project\\nGutenberg™ electronic works to protect the PROJECT GUTENBERG™\\nconcept and trademark. Project Gutenberg is a registered trademark,\\nand may not be used if you charge for an eBook, except by following\\nthe terms of the trademark license, including paying royalties for use\\nof the Project Gutenberg trademark. If you do not charge anything for\\ncopies of this eBook, complying with the trademark license is very\\neasy. You may use this eBook for nearly any purpose such as creation\\nof derivative works, reports, performances and research. Project\\nGutenberg eBooks may be modified and printed and given away—you may\\ndo practically ANYTHING in the United States with eBooks not protected\\nby U.S. copyright law. Redistribution is subject to the trademark\\nlicense, especially commercial redistribution.\\n\\n\\nSTART: FULL LICENSE\\n\\nTHE FULL PROJECT GUTENBERG LICENSE\\n\\nPLEASE READ THIS BEFORE YOU DISTRIBUTE OR USE THIS WORK'),\n",
       " Document(metadata={'id': '3', 'source': '../../data/The Project Gutenberg eBook of A Christmas Carol in Prose; Being a Ghost Story of Christmas.txt'}, page_content='Once upon a time--of all the good days in the year,\\non Christmas Eve--old Scrooge sat busy in his\\ncounting-house. It was cold, bleak, biting weather: foggy\\nwithal: and he could hear the people in the court outside,\\ngo wheezing up and down, beating their hands\\nupon their breasts, and stamping their feet upon the\\npavement stones to warm them. The city clocks had\\nonly just gone three, but it was quite dark already--\\nit had not been light all day--and candles were flaring\\nin the windows of the neighbouring offices, like\\nruddy smears upon the palpable brown air. The fog\\ncame pouring in at every chink and keyhole, and was\\nso dense without, that although the court was of the\\nnarrowest, the houses opposite were mere phantoms.\\nTo see the dingy cloud come drooping down, obscuring\\neverything, one might have thought that Nature\\nlived hard by, and was brewing on a large scale.\\n\\nThe door of Scrooge\\'s counting-house was open\\nthat he might keep his eye upon his clerk, who in a\\ndismal little cell beyond, a sort of tank, was copying\\nletters. Scrooge had a very small fire, but the clerk\\'s\\nfire was so very much smaller that it looked like one\\ncoal. But he couldn\\'t replenish it, for Scrooge kept\\nthe coal-box in his own room; and so surely as the\\nclerk came in with the shovel, the master predicted\\nthat it would be necessary for them to part. Wherefore\\nthe clerk put on his white comforter, and tried to\\nwarm himself at the candle; in which effort, not being\\na man of a strong imagination, he failed.\\n\\n\"A merry Christmas, uncle! God save you!\" cried\\na cheerful voice. It was the voice of Scrooge\\'s\\nnephew, who came upon him so quickly that this was\\nthe first intimation he had of his approach.\\n\\n\"Bah!\" said Scrooge, \"Humbug!\"\\n\\nHe had so heated himself with rapid walking in the\\nfog and frost, this nephew of Scrooge\\'s, that he was\\nall in a glow; his face was ruddy and handsome; his\\neyes sparkled, and his breath smoked again.'),\n",
       " Document(metadata={'id': '8', 'source': '../../data/The Project Gutenberg eBook of A Christmas Carol in Prose; Being a Ghost Story of Christmas.txt'}, page_content=\"Meanwhile the fog and darkness thickened so, that\\npeople ran about with flaring links, proffering their\\nservices to go before horses in carriages, and conduct\\nthem on their way. The ancient tower of a church,\\nwhose gruff old bell was always peeping slily down\\nat Scrooge out of a Gothic window in the wall, became\\ninvisible, and struck the hours and quarters in the\\nclouds, with tremulous vibrations afterwards as if\\nits teeth were chattering in its frozen head up there.\\nThe cold became intense. In the main street, at the\\ncorner of the court, some labourers were repairing\\nthe gas-pipes, and had lighted a great fire in a brazier,\\nround which a party of ragged men and boys were\\ngathered: warming their hands and winking their\\neyes before the blaze in rapture. The water-plug\\nbeing left in solitude, its overflowings sullenly congealed,\\nand turned to misanthropic ice. The brightness\\nof the shops where holly sprigs and berries\\ncrackled in the lamp heat of the windows, made pale\\nfaces ruddy as they passed. Poulterers' and grocers'\\ntrades became a splendid joke: a glorious pageant,\\nwith which it was next to impossible to believe that\\nsuch dull principles as bargain and sale had anything\\nto do. The Lord Mayor, in the stronghold of the\\nmighty Mansion House, gave orders to his fifty cooks\\nand butlers to keep Christmas as a Lord Mayor's\\nhousehold should; and even the little tailor, whom he\\nhad fined five shillings on the previous Monday for\\nbeing drunk and bloodthirsty in the streets, stirred up\\nto-morrow's pudding in his garret, while his lean\\nwife and the baby sallied out to buy the beef.\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=4  # return 3 most relevant docs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the index with LanChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of A Christmas Carol in Prose; Being a Ghost Story of Christmas\n",
      "\n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "\n",
      "Title: A Christmas Carol in Prose; Being a Ghost Story of Christmas\n",
      "\n",
      "\n",
      "Author: Charles Dickens\n",
      "\n",
      "Illustrator: John Leech\n",
      "\n",
      "Release date: August 11, 2004 [eBook #46]\n",
      "                Most recently updated: October 17, 2021\n",
      "\n",
      "Language: English\n",
      "\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK A CHRISTMAS CAROL IN PROSE; BEING A GHOST STORY OF CHRISTMAS ***\n",
      "\n",
      "A CHRISTMAS CAROL\n",
      "\n",
      "IN PROSE\n",
      "BEING\n",
      "A Ghost Story of Christmas\n",
      "\n",
      "by Charles Dickens\n",
      "\n",
      "PREFACE\n",
      "\n",
      "I HAVE endeavoured in this Ghostly little book,\n",
      "to raise the Ghost of an Idea, which shall not put my\n",
      "readers out of humour with themselves, with each other,\n",
      "with the season, or with me.  May it haunt their houses\n",
      "pleasantly, and no one wish to lay it.\n",
      "\n",
      "Their faithful Friend and Servant,\n",
      "                                   C. D.\n",
      "December, 1843.\n",
      "\n",
      "CONTENTS\n",
      "\n",
      "Stave   I: Marley's Ghost\n",
      "Stave  II: The First of the Three Spirits\n",
      "Stave III: The Second of the Three Spirits\n",
      "Stave  IV: The Last of the Spirits\n",
      "Stave   V: The End of It\n",
      "\n",
      "STAVE I:  MARLEY'S GHOST\n",
      "\n",
      "MARLEY was dead: to begin with. There is no doubt\n",
      "whatever about that. The register of his burial was\n",
      "signed by the clergyman, the clerk, the undertaker,\n",
      "and the chief mourner. Scrooge signed it: and\n",
      "Scrooge's name was good upon 'Change, for anything he\n",
      "chose to put his hand to. Old Marley was as dead as a\n",
      "door-nail.\n",
      "\n",
      "The function took an average of 0.26 seconds to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNow, we compare to PGVector, an open source vector store service.\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_query_pinecone(docsearch: PineconeVectorStore, query: str):\n",
    "    docs = docsearch.similarity_search(query, k=4)\n",
    "    result = docs[0].page_content\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_average_execution_time(func, *args, **kwargs):\n",
    "    total_execution_time = 0\n",
    "    num_runs = 10\n",
    "    for _ in range(num_runs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)  # Execute the function with its arguments\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        total_execution_time += execution_time\n",
    "    average_execution_time = round(total_execution_time / num_runs, 2)\n",
    "    print(result)\n",
    "    print(\n",
    "        f\"\\nThe function took an average of {average_execution_time} seconds to execute.\"\n",
    "    )\n",
    "    return\n",
    "\n",
    "\n",
    "calculate_average_execution_time(\n",
    "    run_query_pinecone, docsearch=vectorstore, query=query\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Now, we compare to PGVector, an open source vector store service.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a PGVector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">postgresql+psycopg:<span style=\"color: #800080; text-decoration-color: #800080\">//</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">langchain</span>:langchain@localhost:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6432</span>/langchain\n",
       "</pre>\n"
      ],
      "text/plain": [
       "postgresql+psycopg:\u001b[35m/\u001b[0m\u001b[35m/\u001b[0m\u001b[95mlangchain\u001b[0m:langchain@localhost:\u001b[1;36m6432\u001b[0m/langchain\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolm/.pyenv/versions/3.10.14/envs/rag_techniques3/lib/python3.10/site-packages/langchain_community/vectorstores/pgvector.py:328: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata.Please note that filtering operators have been changed when using JSOB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create adb migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  warn_deprecated(\n",
      "/Users/malcolm/.pyenv/versions/3.10.14/envs/rag_techniques3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainPendingDeprecationWarning: This class is pending deprecation and may be removed in a future version. You can swap to using the `PGVector` implementation in `langchain_postgres`. Please read the guidelines in the doc-string of this class to follow prior to migrating as there are some differences between the implementations. See <https://github.com/langchain-ai/langchain-postgres> for details aboutthe new implementation.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Donwload postgresql to run locally:\n",
    "https://www.postgresql.org/download/\n",
    "\n",
    "How to install the pgvector extension:\n",
    "https://github.com/pgvector/pgvector\n",
    "\n",
    "Fix common installation issues:\n",
    "https://github.com/pgvector/pgvector?tab=readme-ov-file#installation-notes\n",
    "\"\"\"\n",
    "\n",
    "COLLECTION_NAME = \"The Project Gutenberg eBook of A Christmas Carol in Prose\"\n",
    "\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(\n",
    "    driver=os.environ.get(\"PGVECTOR_DRIVER\", \"psycopg\"),\n",
    "    host=os.environ.get(\"PGVECTOR_HOST\", \"localhost\"),\n",
    "    port=int(os.environ.get(\"PGVECTOR_PORT\", \"6432\")),\n",
    "    database=os.environ.get(\"PGVECTOR_DATABASE\", \"langchain\"),\n",
    "    user=os.environ.get(\"PGVECTOR_USER\", \"langchain\"),\n",
    "    password=os.environ.get(\"PGVECTOR_PASSWORD\", \"langchain\"),\n",
    ")\n",
    "\n",
    "rich.print(CONNECTION_STRING)\n",
    "\n",
    "DATABASE_URL = \"postgresql+psycopg://langchain:langchain@localhost:6432/langchain\"\n",
    "\n",
    "# create the store\n",
    "db = PGVector.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=docs,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection=False,\n",
    "    ids=[doc.metadata[\"id\"] for doc in docs]\n",
    ")\n",
    "\n",
    "# load the store\n",
    "pgvector_docsearch = PGVector(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    embedding_function=embeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the index with PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of A Christmas Carol in Prose; Being a Ghost Story of Christmas\n",
      "\n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "\n",
      "Title: A Christmas Carol in Prose; Being a Ghost Story of Christmas\n",
      "\n",
      "\n",
      "Author: Charles Dickens\n",
      "\n",
      "Illustrator: John Leech\n",
      "\n",
      "Release date: August 11, 2004 [eBook #46]\n",
      "                Most recently updated: October 17, 2021\n",
      "\n",
      "Language: English\n",
      "\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK A CHRISTMAS CAROL IN PROSE; BEING A GHOST STORY OF CHRISTMAS ***\n",
      "\n",
      "A CHRISTMAS CAROL\n",
      "\n",
      "IN PROSE\n",
      "BEING\n",
      "A Ghost Story of Christmas\n",
      "\n",
      "by Charles Dickens\n",
      "\n",
      "PREFACE\n",
      "\n",
      "I HAVE endeavoured in this Ghostly little book,\n",
      "to raise the Ghost of an Idea, which shall not put my\n",
      "readers out of humour with themselves, with each other,\n",
      "with the season, or with me.  May it haunt their houses\n",
      "pleasantly, and no one wish to lay it.\n",
      "\n",
      "Their faithful Friend and Servant,\n",
      "                                   C. D.\n",
      "December, 1843.\n",
      "\n",
      "CONTENTS\n",
      "\n",
      "Stave   I: Marley's Ghost\n",
      "Stave  II: The First of the Three Spirits\n",
      "Stave III: The Second of the Three Spirits\n",
      "Stave  IV: The Last of the Spirits\n",
      "Stave   V: The End of It\n",
      "\n",
      "STAVE I:  MARLEY'S GHOST\n",
      "\n",
      "MARLEY was dead: to begin with. There is no doubt\n",
      "whatever about that. The register of his burial was\n",
      "signed by the clergyman, the clerk, the undertaker,\n",
      "and the chief mourner. Scrooge signed it: and\n",
      "Scrooge's name was good upon 'Change, for anything he\n",
      "chose to put his hand to. Old Marley was as dead as a\n",
      "door-nail.\n",
      "\n",
      "The function took an average of 0.22 seconds to execute.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_query_pgvector(docsearch: PineconeVectorStore, query: str):\n",
    "    docs = docsearch.similarity_search(query, k=4)\n",
    "    result = docs[0].page_content\n",
    "    return result\n",
    "\n",
    "\n",
    "calculate_average_execution_time(\n",
    "    run_query_pgvector, docsearch=pgvector_docsearch, query=query\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add more collections to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolm/.pyenv/versions/3.10.14/envs/rag_techniques3/lib/python3.10/site-packages/langchain_community/vectorstores/pgvector.py:328: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata.Please note that filtering operators have been changed when using JSOB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create adb migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader = TextLoader(\"../../data/The Project Gutenberg eBook of Romeo and Juliet.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "new_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "# Create a unique ID for each document\n",
    "# SOURCE: https://github.com/theonemule/azure-rag-sample/blob/1e37de31678ffbbe5361a8ef3acdb770194f462a/import.py#L4\n",
    "for idx, doc in enumerate(new_docs):\n",
    "    doc.metadata[\"id\"] = str(idx)\n",
    "\n",
    "COLLECTION_NAME_2 = \"The Project Gutenberg eBook of Romeo and Juliet\"\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=new_docs,\n",
    "    collection_name=COLLECTION_NAME_2,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection=False,\n",
    "    ids=[doc.metadata[\"id\"] for doc in new_docs]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the index with multiple collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pg = PgvectorService(CONNECTION_STRING)\n",
    "\n",
    "\n",
    "def run_query_multi_pgvector(docsearch, query):\n",
    "    docs = docsearch.custom_similarity_search_with_scores(query, k=4)\n",
    "    result = docs[0][0].page_content\n",
    "    print(result)\n",
    "\n",
    "\n",
    "run_query_multi_pgvector(pg, query)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Delete the collection\n",
    "# --------------------------------------------------------------\n",
    "pg.delete_collection(COLLECTION_NAME)\n",
    "pg.delete_collection(COLLECTION_NAME_2)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Update the collection\n",
    "# --------------------------------------------------------------\n",
    "pg.update_collection(docs=docs, collection_name=COLLECTION_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look into https://medium.com/@towards-agi/dont-use-pinecone-or-milvus-for-vector-database-pgvector-is-70-faster-and-cheaper-and-open-66a698358415\n",
    "\n",
    "We probably need to enable some of these items and should think about how it would look to run locally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
